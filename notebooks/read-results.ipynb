{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da6de9-439b-4336-94d7-2dadc0c769fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/jens/PycharmProjects/arbfree-dyn-ns\")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "from pandas import Timestamp\n",
    "import statsmodels.api as sm\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from arbfree_dyn_ns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be169ad1-fa16-4a06-8041-a73dffef66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_BASE_PATH = PKL_BASE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0991df-fbe1-4c47-b3c0-5a03aef363f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = { p.name: pd.read_pickle(p)\n",
    "         for p in sorted(RESULTS_BASE_PATH.glob(\"main*.pkl\"))\n",
    "           if file_name_to_datetime(p) > datetime.datetime(2024, 1, 2, 14, 38)\n",
    "              #and (\"Wkly\" if frequency_weekly else \"Mthly\") in p.name and cutoff.strftime(\"%y%m%d\") in p.name\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ddff2-0678-4825-82c8-d21c56064cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_str(i, n):\n",
    "    # test: [[i_str(i, n) for i in range(n)] for n in [3, 5]]\n",
    "    return (\"level\" if i == 0\n",
    "             else \"slope1\" if i == 1\n",
    "             else \"slope2\" if i == 2 and n == 5\n",
    "             else \"curvature1\" if i == 2\n",
    "             else \"curvature1\" if i == 3\n",
    "             else \"curvature2\")\n",
    "\n",
    "results_dissected = {}\n",
    "for key, result in results.items():\n",
    "    results_dissected[key] = dict(zip((\"optres\", \"H_opt\", \"K_opt\", \"Sigma_opt\", \"lambda_opt\", \"lambda_svensson_opt\", \"theta_opt\", \n",
    "                \"theta_xs\", \"K_xs\", \"H_xs\", \"Sigma_xs\", \"loglikelihood_xs\", \"lambda_xs\", \"lambda_svensson_xs\", \"n_ev\"), result))\n",
    "    results_dissected[key].update(dict(results_dissected[key][\"optres\"]))\n",
    "    results_dissected[key][\"yield_adjustment_term_included\"] = \"True\" in key\n",
    "    dissected_file_name = dissect_file_name(key)\n",
    "    if dissected_file_name is not None:\n",
    "        results_dissected[key].update(dissected_file_name)\n",
    "    for k in (\"H_opt\", \"K_opt\", \"Sigma_opt\", \"theta_opt\"):\n",
    "        if k != \"theta_opt\":\n",
    "            results_dissected[key][k] = np.diagonal(results_dissected[key][k])\n",
    "        n = len(results_dissected[key][k])\n",
    "        results_dissected[key][\"n\"] = n\n",
    "        if n in (3, 5):\n",
    "            for i in range(n):\n",
    "                results_dissected[key][k + \"_\" + i_str(i, n)] = results_dissected[key][k][i]\n",
    "    #print(results_dissected[key].keys())\n",
    "    results_dissected[key] = pd.Series(results_dissected[key])\n",
    "results_dissected = pd.DataFrame(results_dissected).T\n",
    "\n",
    "results_dissected = results_dissected.join(results_dissected[\"yields\"].apply(\n",
    "    lambda df: pd.Series({\"timeframe_start\": df.index.min() if hasattr(df, \"index\") else pd.Timestamp(\"1970-01-01\"),\n",
    "                          \"timeframe_end\": df.index.max() if hasattr(df, \"index\") else pd.Timestamp(\"1970-01-01\")})),\n",
    "                       how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b404b501-ff6e-44cf-941c-5b42caf693bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['fun', 'message', 'n', 'yield_adjustment_term_included', 'timeframe_start',\n",
    "       'timeframe_end', 'data_source', 'frequency', 'K_opt_level', 'K_opt_slope1', 'K_opt_slope2', 'K_opt_curvature1', 'K_opt_curvature2',\n",
    "                       'Sigma_opt_level', 'Sigma_opt_slope1', 'Sigma_opt_slope2', 'Sigma_opt_curvature1', 'Sigma_opt_curvature2',\n",
    "                       'theta_opt_level', 'theta_opt_slope1', 'theta_opt_slope2', 'theta_opt_curvature1', 'theta_opt_curvature2',\n",
    "        'lambda_opt',\n",
    "       'lambda_svensson_opt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d514e-10a1-46ee-8c15-e5156c825b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dissected[columns_of_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65bb0b-e691-4b03-8014-dd5da2173c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dissected[columns_of_interest].to_excel(RESULTS_BASE_PATH / \"results_dissected20240103.xlsx\", freeze_panes=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd0f42-df46-4023-8af9-9249437a69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_dissected[columns_of_interest].to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30d585-359a-4cbf-ae2f-fcc88d795c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(key=widgets.Dropdown(options=results.keys(),\n",
    "                                      layout={'width': 'max-content'}))\n",
    "def f(key):\n",
    "    optres, H_opt, K_opt, Sigma_opt, lambda_opt, lambda_svensson_opt, theta_opt, \\\n",
    "            theta_xs, K_xs, H_xs, Sigma_xs, loglikelihood_xs, lambda_xs, lambda_svensson_xs, n_ev = results[key]\n",
    "    display(optres)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    print(\"jac     =\", optres.jac, end=\"\\n\\n\")\n",
    "    print(\"H       =\", np.diagonal(H_opt), end=\"\\n\\n\")\n",
    "    print(\"K       =\", np.diagonal(K_opt), end=\"\\n\\n\")\n",
    "    print(\"Sigma   =\", np.diagonal(Sigma_opt), end=\"\\n\\n\")\n",
    "    print(\"lambda1 =\", lambda_opt, end=\"\\n\\n\")\n",
    "    print(\"lambda2 =\", lambda_svensson_opt, end=\"\\n\\n\")\n",
    "    print(\"theta   =\", theta_opt, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040d5d5-774c-46aa-ad17-35b34002b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_error_described_apriori = {}\n",
    "error_described_apriori = {}\n",
    "squared_error_described_apost = {}\n",
    "error_described_apost = {}\n",
    "\n",
    "def run_kalman_for_opt_params(key, silent=False, save_plots=False):\n",
    "    #print(key)\n",
    "    if \"TEST\" in key:\n",
    "        yields = afgns_data()[1]\n",
    "        time_step_size = 1/12\n",
    "    else:\n",
    "        gd = dissect_file_name(key)\n",
    "        yields = gd[\"yields\"]\n",
    "        time_step_size = 7/365.2425 if gd[\"frequency\"] == \"Wkly\" else 1/12\n",
    "    grid = yields.columns.rename(\"tenor\")\n",
    "    if not silent:\n",
    "        print(grid)\n",
    "\n",
    "    \n",
    "    result = results[key]\n",
    "    optres, H_opt, K_opt, Sigma_opt, lambda_opt, lambda_svensson_opt, theta_opt, \\\n",
    "                theta_xs, K_xs, H_xs, Sigma_xs, loglikelihood_xs, lambda_xs, lambda_svensson_xs, n_ev = result\n",
    "\n",
    "    B_opt = B_matrix(lambda_opt, grid, lambda_svensson_value=lambda_svensson_opt)\n",
    "    B_for_optimization = B_opt.to_numpy()\n",
    "    if \"True\" in key:\n",
    "        c_vector = C_vector(lambda_opt, grid, K_times_theta=None, Sigma=Sigma_opt, lambda_svensson_value=lambda_svensson_opt)\n",
    "        c_vector = c_vector.to_numpy()\n",
    "    else:\n",
    "        c_vector = None\n",
    "    \n",
    "    \n",
    "    A_opt = scipy.linalg.expm(-time_step_size * K_opt)\n",
    "    Q_opt = compute_Q(K_opt, Sigma_opt, time_step_size)\n",
    "\n",
    "  \n",
    "    kalman_res = kalman_filter(yields, theta_opt, A_opt, H_opt, Q_opt, B=B_for_optimization,\n",
    "                            exclude_first_observations_for_loglikelihood=min(10, .05 * len(yields)),\n",
    "                            c=c_vector)  # , no_tqdm=no_tqdm)[1]\n",
    "    x, loglikelihood, loglikelihood_contribution, P, F, v, x_next = kalman_res\n",
    "    \n",
    "    if not silent:\n",
    "        print(loglikelihood)\n",
    "        print(theta_opt)\n",
    "        ax = pd.DataFrame(v, index=x.index, columns=grid).iloc[2:].plot()\n",
    "        if save_plots:\n",
    "            ax.get_figure().savefig(RESULTS_BASE_PATH / (key + \"errors.svg\"))\n",
    "    if key not in squared_error_described_apost.keys():\n",
    "        xtt = np.array([xtt_numba(x.iloc[i].to_numpy(), P[i], B_for_optimization, v[i], np.linalg.inv(F[i]))\n",
    "                    for i in range(len(yields))], dtype=float)\n",
    "        vtt = np.array([y.to_numpy() - B_for_optimization @ xtt_ for (i, y), xtt_ in zip(yields.iterrows(), xtt)],\n",
    "                      dtype=float)\n",
    "        if c_vector is not None:\n",
    "            vtt = np.array([vtt_ - c_vector for vtt_ in vtt], dtype=float)\n",
    "        \n",
    "        for the_v, (squared_error_described, error_described) in ((v, (squared_error_described_apriori, error_described_apriori)),\n",
    "                                                                  (vtt, (squared_error_described_apost, error_described_apost))):\n",
    "            v_mat = pd.DataFrame(the_v, index=x.index, columns=grid).iloc[2:]\n",
    "            error_described[key] = v_mat.describe()\n",
    "            squared_error_described[key] = (v_mat ** 2).describe()\n",
    "    if not silent:\n",
    "        rename_dict = dict(enumerate([\"level\", \"slope\", \"curvature\"])) if x.shape[1] == 3 \\\n",
    "                        else dict(enumerate([\"level\", \"slope1\", \"slope2\", \"curvature1\", \"curvature2\"]))\n",
    "        ax = x.rename(rename_dict, axis=1).plot(style=[\"-\", \"--\", \":\"] if x.shape[1] == 3 else [\"-\", \"--\", \"--\", \":\", \":\"])\n",
    "        if save_plots:\n",
    "            ax.get_figure().savefig(RESULTS_BASE_PATH / (key + \"X.svg\"))\n",
    "        if c_vector is not None:\n",
    "            display(pd.Series(c_vector, index=grid))\n",
    "    #(B_opt @ theta_opt).plot()\n",
    "\n",
    "\n",
    "widgets.interact(key=widgets.Dropdown(options=results.keys(),\n",
    "                                      layout={'width': 'max-content'}))(run_kalman_for_opt_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d0707-7ebc-4c60-9999-5653753aba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate svgs\n",
    "for k in results.keys():\n",
    "    if \"TEST\" not in k and k not in squared_error_described_apriori.keys():\n",
    "        run_kalman_for_opt_params(k, silent=False, save_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d6331-5969-48c7-9fc2-962a87625057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill squared_error_described\n",
    "for k in results.keys():\n",
    "    if \"TEST\" not in k and k not in squared_error_described_apriori.keys():\n",
    "        run_kalman_for_opt_params(k, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdd88b8-36be-4797-b0d8-4e29414b890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_by_tenor = { key: pd.concat(squared_error_described_apriori if key == \"apriori\" else squared_error_described_apost)\\\n",
    "                       .xs(\"mean\", level=1) ** (1/2) * 1e4\n",
    "                 for key in (\"apost\", \"apriori\")}\n",
    "\n",
    "me_by_tenor = { key: pd.concat(error_described_apriori if key == \"apriori\" else error_described_apost)\\\n",
    "                       .xs(\"mean\", level=1) * 1e4\n",
    "                 for key in (\"apost\", \"apriori\")}\n",
    "\n",
    "rmse = { key: pd.concat(squared_error_described_apriori if key == \"apriori\" else squared_error_described_apost)\\\n",
    "                       .xs(\"mean\", level=1).mean(axis=1) ** (1/2) * 1e4\n",
    "                 for key in (\"apost\", \"apriori\")}\n",
    "\n",
    "me = { key: pd.concat(error_described_apriori if key == \"apriori\" else error_described_apost)\\\n",
    "                       .xs(\"mean\", level=1).mean(axis=1) * 1e4\n",
    "                 for key in (\"apost\", \"apriori\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadc3e6-478b-446a-a7d8-74ecb1b7eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = pd.concat({\"rmse\": pd.concat(rmse_by_tenor).join(pd.concat(rmse).rename(\"total\")),\n",
    "                    \"me\":   pd.concat(me_by_tenor  ).join(pd.concat(me  ).rename(\"total\"))}).swaplevel(0,2).swaplevel(1,2)\n",
    "errors.index.rename([\"pkl_name\", \"error_type\", \"knowledge\"], inplace=True)\n",
    "errors = results_dissected[[\"n\", \"yield_adjustment_term_included\", \"timeframe_start\", \"timeframe_end\", \"data_source\", \"frequency\"]].merge(\n",
    "    errors, right_on=\"pkl_name\", left_index=True, how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229df75-3770-4607-bbff-424bf9705140",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.to_excel(RESULTS_BASE_PATH / \"errors20240103.xlsx\", freeze_panes=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0be036f-2be7-4473-a8fe-21be250efef5",
   "metadata": {},
   "source": [
    "# LaTeX Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f8cbe-0eb5-40c8-a38e-14547e914e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precise_timeframes = errors[[\"data_source\", \"frequency\", \"timeframe_start\", \"timeframe_end\"]].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606b8ab-a680-45f7-ade7-b7af7e1acb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['timeframe', 'frequency', 'n',\n",
    "              'yield_adjustment_term_included', \n",
    "              'data_source'\n",
    "             ]\n",
    "\n",
    "errors_latex = errors.copy().droplevel(level=0).reset_index()\n",
    "errors_latex[\"timeframe\"] = errors_latex[\"timeframe_start\"].dt.strftime(\"%y\") + \"--\" + errors_latex[\"timeframe_end\"].dt.strftime(\"%y\")\n",
    "errors_latex.sort_values([\"data_source\", \"frequency\", \"timeframe_end\", \"timeframe_start\",\n",
    "                          \"n\", \"yield_adjustment_term_included\"], inplace=True)\n",
    "errors_latex = errors_latex[errors_latex[\"timeframe_end\"].dt.year != 2008]\n",
    "errors_latex = errors_latex.drop([\"timeframe_start\", \"timeframe_end\"], axis=1).set_index(index_cols)\n",
    "errors_latex = errors_latex[[\"error_type\", \"knowledge\", 1, 2, 3, 5, 10, 15, 20, 25, \"total\"]]\n",
    "\n",
    "results_dissected_latex = results_dissected.loc[~results_dissected[\"data_source\"].isna(), columns_of_interest].copy()\\\n",
    "                        .reset_index(drop=True)\\\n",
    "                        .drop([\"message\"], axis=1).rename({\"fun\": \"loglikelihood\",\n",
    "                                                      }, axis=1)\n",
    "results_dissected_latex[\"loglikelihood\"] = results_dissected_latex[\"loglikelihood\"].abs()\n",
    "results_dissected_latex[\"timeframe\"] = results_dissected_latex[\"timeframe_start\"].dt.strftime(\"%y\") + \"--\" + results_dissected_latex[\"timeframe_end\"].dt.strftime(\"%y\")\n",
    "results_dissected_latex.sort_values([\"data_source\", \"frequency\", \"timeframe_end\", \"timeframe_start\",\n",
    "                                     \"n\", \"yield_adjustment_term_included\"], inplace=True)\n",
    "results_dissected_latex = results_dissected_latex[results_dissected_latex[\"timeframe_end\"].dt.year != 2008]\n",
    "results_dissected_latex = results_dissected_latex.drop([\"timeframe_start\", \"timeframe_end\"], axis=1).set_index(index_cols)\n",
    "\n",
    "formatters = {column_name: f\"{{:0.{digits}f}}\".format\n",
    "                for column_name, digits in \n",
    "                ((\"loglikelihood\", 1),\n",
    "                 (\"K_opt_slope1\", 2),\n",
    "                 (\"K_opt_slope2\", 2),\n",
    "                 (\"K_opt_level\", 2),\n",
    "                 (\"K_opt_curvature1\", 2),\n",
    "                 (\"K_opt_curvature2\", 2),\n",
    "                 (\"Sigma_opt_level\", 4),\n",
    "                 (\"Sigma_opt_slope1\", 4),\n",
    "                 (\"Sigma_opt_slope2\", 4),\n",
    "                 (\"Sigma_opt_curvature1\", 4),\n",
    "                 (\"Sigma_opt_curvature2\", 4),\n",
    "                 (\"theta_opt_level\", 4),\n",
    "                 (\"theta_opt_slope1\", 4),\n",
    "                 (\"theta_opt_slope2\", 4),\n",
    "                 (\"theta_opt_curvature1\", 4),\n",
    "                 (\"theta_opt_curvature2\", 4),\n",
    "                 (\"lambda_opt\", 4),\n",
    "                 (\"lambda_svensson_opt\", 4),\n",
    "                )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0772540-6e40-4db2-8e08-1600e9d4a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_latex_sub = {(error_type, knowledge):\n",
    "        errors_latex.query(f\"error_type == '{error_type}' and knowledge == '{knowledge}'\").drop([\"error_type\", \"knowledge\"], axis=1)\n",
    "    for error_type, knowledge in errors_latex[[\"error_type\", \"knowledge\"]].drop_duplicates().values }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad2c1f-398f-45a0-82b7-066f9b2e1503",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (error_type, knowledge), df in errors_latex_sub.items():\n",
    "    for data_source in (\"lw\", \"buba\"):\n",
    "        df2 = df.query(f\"data_source=='{data_source}'\").copy()\n",
    "        df2 = df2.droplevel(\"frequency\" if data_source == \"lw\" else \"timeframe\").droplevel(\"data_source\")\n",
    "        out = df2.to_latex(na_rep=\"---\", sparsify=False, float_format=\"%.2f\" if error_type != \"me\" else \"%.2f\")\\\n",
    "                .replace(\" 00:00:00\", \"\")\\\n",
    "                .replace(\" buba \", \" BuBa \")\\\n",
    "                .replace(\" lw \", \" Liu-Wu \")\\\n",
    "                .replace(\"Mthly \", \"M \")\\\n",
    "                .replace(\"Wkly \", \"W \")\\\n",
    "                .replace(\" False \", \" no \")\\\n",
    "                .replace(\" True \", \" yes \")\\\n",
    "                .replace(\".000000\", \"\")\n",
    "        with open(RESULTS_BASE_PATH / f\"errors_{error_type}_{knowledge}__{data_source}.inc\", \"w\") as f:\n",
    "            print(out, file=f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d3a2b-d21d-4a9d-9b58-35be3d6a19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dissected_subset_definitions = {'loglikelihood_and_lambda': ['loglikelihood', \"lambda_opt\", \"lambda_svensson_opt\"],\n",
    "                                        'K': [c for c in results_dissected_latex.columns if c.startswith(\"K_\")],\n",
    "                                        'Sigma': [c for c in results_dissected_latex.columns if c.startswith(\"Sigma_\")],\n",
    "                                        'theta': [c for c in results_dissected_latex.columns if c.startswith(\"theta_\")],\n",
    "                                       }\n",
    "\n",
    "results_dissected_latex_sub = { subset_name: results_dissected_latex[subset_columns]\n",
    "                               for subset_name, subset_columns in results_dissected_subset_definitions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44948560-50dd-4426-a91d-da18c27927b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = results_dissected_latex.to_latex(formatters=formatters, na_rep=\"---\", sparsify=False)\\\n",
    "    .replace(\" 00:00:00\", \"\")\\\n",
    "    .replace(\" buba \", \" BuBa \")\\\n",
    "    .replace(\" lw \", \" Liu-Wu \")\\\n",
    "    .replace(\" Mthly \", \" M \")\\\n",
    "    .replace(\" Wkly \", \" W \")\\\n",
    "    .replace(\" False \", \" no \")\\\n",
    "    .replace(\" True \", \" yes \")\n",
    "with open(RESULTS_BASE_PATH / \"results_dissected.inc\", \"w\") as f:\n",
    "    print(out, file=f)\n",
    "\n",
    "for subset_name, df in results_dissected_latex_sub.items():\n",
    "    for data_source in (\"lw\", \"buba\"):\n",
    "        df2 = df.query(f\"data_source=='{data_source}'\").copy()\n",
    "        df2 = df2.droplevel(\"frequency\" if data_source == \"lw\" else \"timeframe\").droplevel(\"data_source\")\n",
    "        out = df2.to_latex(formatters=formatters, na_rep=\"---\", sparsify=False)\\\n",
    "        .replace(\" 00:00:00\", \"\")\\\n",
    "        .replace(\" buba \", \" BuBa \")\\\n",
    "        .replace(\" lw \", \" Liu-Wu \")\\\n",
    "        .replace(\"Mthly \", \"M \")\\\n",
    "        .replace(\"Wkly \", \"W \")\\\n",
    "        .replace(\" False \", \" no \")\\\n",
    "        .replace(\" True \", \" yes \")\n",
    "        with open(RESULTS_BASE_PATH / f\"results_dissected_{subset_name}__{data_source}.inc\", \"w\") as f:\n",
    "            print(out, file=f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438303f-ad4a-459a-99cd-7fa3acf45afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = precise_timeframes.to_latex(index=False)\\\n",
    "    .replace(\" 00:00:00\", \"\")\\\n",
    "    .replace(\" buba \", \" BuBa \")\\\n",
    "    .replace(\" lw \", \" Liu-Wu \")\\\n",
    "    .replace(\"Mthly \", \"M \")\\\n",
    "    .replace(\"Wkly \", \"W \")\\\n",
    "    .replace(\" False \", \" no \")\\\n",
    "    .replace(\" True \", \" yes \")\n",
    "with open(RESULTS_BASE_PATH / \"precise_timeframes.inc\", \"w\") as f:\n",
    "    print(out, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9a1e2c-9d48-4047-b991-30c7dc28dd77",
   "metadata": {},
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ceeec1-14a9-4b99-bcd8-ac147e26db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_opt(key, save_plot=False):\n",
    "    if \"TEST\" in key:\n",
    "        yields = afgns_data()[1]\n",
    "        time_step_size = 1/12\n",
    "    else:\n",
    "        gd = dissect_file_name(key)\n",
    "        yields = gd[\"yields\"]\n",
    "        time_step_size = 7/365.2425 if gd[\"frequency\"] == \"Wkly\" else 1/12\n",
    "    grid = yields.columns\n",
    "    result = results[key]\n",
    "    optres, H_opt, K_opt, Sigma_opt, lambda_opt, lambda_svensson_opt, theta_opt, \\\n",
    "                theta_xs, K_xs, H_xs, Sigma_xs, loglikelihood_xs, lambda_xs, lambda_svensson_xs, n_ev = result\n",
    "\n",
    "    B_opt = B_matrix(lambda_opt, grid, lambda_svensson_value=lambda_svensson_opt)\n",
    "    B_for_optimization = B_opt.to_numpy()\n",
    "    c = C_vector(lambda_opt, grid, K_times_theta=None, Sigma=Sigma_opt, lambda_svensson_value=lambda_svensson_opt)\n",
    "    c.index.rename(\"tenor\", inplace=True)\n",
    "    c = c.rename(\"yield adjustment term -C(tenor)/tenor\")\n",
    "    if save_plot:\n",
    "        c.plot(marker=\"o\").get_figure().savefig(RESULTS_BASE_PATH / (key + \"C.svg\"))\n",
    "        plt.close()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337b2a62-4aeb-4919-8f6b-1717de3a1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results.keys():\n",
    "    c_opt(key, save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129c101-1809-4841-a9b9-76b9f69c0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_opt(next(iter(results.keys()))).plot(marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ad84b-519b-4834-a176-16b908d58900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe34bda-ed9a-4253-bdd0-44b86f678725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffae03-61c9-491e-bb7f-ed7c4ef069ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
